{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from datasets import load_dataset\n\n# Load XSum dataset\ndataset_samsum = load_dataset('xsum')\n\n# Define the percentage of the data to keep\ntrain_precent = 0.4\ntest_and_val_percent = 0.6\n\n# Reduce the size of the train split\ndataset_samsum_train = dataset_samsum['train'].shuffle(seed=42).select(range(int(len(dataset_samsum['train']) * (train_precent/100))))\n\n# Reduce the size of the validation split\ndataset_samsum_validation = dataset_samsum['validation'].shuffle(seed=42).select(range(int(len(dataset_samsum['validation']) * (test_and_val_percent/100))))\n\n# Reduce the size of the test split\ndataset_samsum_test = dataset_samsum['test'].shuffle(seed=42).select(range(int(len(dataset_samsum['test']) * (test_and_val_percent/100))))\n\n# Print the new split sizes\nprint(f\"New split sizes: {[len(dataset_samsum_train), len(dataset_samsum_validation), len(dataset_samsum_test)]}\")\nprint(f\"Features: {dataset_samsum['train'].column_names}\")\n\nprint(f\"\\ndocument:\")\nprint(dataset_samsum[\"test\"][0][\"document\"])\nprint(\"\\nsummary\")\nprint(dataset_samsum[\"test\"][0][\"summary\"])","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-05-12T21:50:04.643997Z","iopub.execute_input":"2023-05-12T21:50:04.644396Z","iopub.status.idle":"2023-05-12T21:50:05.112999Z","shell.execute_reply.started":"2023-05-12T21:50:04.644365Z","shell.execute_reply":"2023-05-12T21:50:05.111907Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"329136c8bef2477fb460c80b033fe1ce"}},"metadata":{}},{"name":"stdout","text":"New split sizes: [816, 67, 68]\nFeatures: ['document', 'summary', 'id']\n\ndocument:\nPrison Link Cymru had 1,099 referrals in 2015-16 and said some ex-offenders were living rough for up to a year before finding suitable accommodation.\nWorkers at the charity claim investment in housing would be cheaper than jailing homeless repeat offenders.\nThe Welsh Government said more people than ever were getting help to address housing problems.\nChanges to the Housing Act in Wales, introduced in 2015, removed the right for prison leavers to be given priority for accommodation.\nPrison Link Cymru, which helps people find accommodation after their release, said things were generally good for women because issues such as children or domestic violence were now considered.\nHowever, the same could not be said for men, the charity said, because issues which often affect them, such as post traumatic stress disorder or drug dependency, were often viewed as less of a priority.\nAndrew Stevens, who works in Welsh prisons trying to secure housing for prison leavers, said the need for accommodation was \"chronic\".\n\"There's a desperate need for it, finding suitable accommodation for those leaving prison there is just a lack of it everywhere,\" he said.\n\"It could take six months to a year, without a lot of help they could be on the streets for six months.\n\"When you think of the consequences of either being on the street, especially with the cold weather at the moment or you may have a roof over your head, sometimes there is only one choice.\"\nMr Stevens believes building more one-bedroom flats could help ease the problem.\n\"The average price is a hundred pounds a week to keep someone in a rented flat, prison is a lot more than that so I would imagine it would save the public purse quite a few pounds,\" he said.\nOfficial figures show 830 one-bedroom properties were built in the year to March 2016, of an overall total of 6,900 new properties in Wales.\nMarc, 50, who has been in and out of prison for the past 20 years for burglary offences, said he struggled to find accommodation each time he was released.\nHe said he would ask himself: \"Where am I going to stay? Where am I going to live? Have I got somewhere where I can see my daughter.\"\n\"You're put out among the same sort of people doing the same sort of thing, and it's difficult, it's difficult to get away from it. It's like every man for himself, there's nothing.\"\nMarc has now found stable accommodation with homeless charity Emmaus and said it had been life changing.\n\"You feel safe, you got hot food, you've got company of people in similar situations to yourself but all dealing with different issues. It's a constructive, helpful atmosphere,\" he said.\nTom Clarke, chief executive of Emmaus South Wales, agreed there was not enough support available.\n\"We do still see [people] homeless on the streets, so clearly they haven't got accommodation and haven't got provision,\" he said.\n\"I think the key is connecting people with the services they need. I don't delude myself that Emmaus can offer a one size fits all for everyone, we can't.\n\"But there must be other opportunities and given suitable encouragement I believe that can and should happen.\"\nA Welsh Government spokesman said the national pathway for homeless services to children, young people and adults in the secure estate had prevented many people from losing their home whilst serving their prison sentence.\nIt added there were already significant demands for one-bedroom flats across the public and private sector and it was providing 20,000 new affordable homes in the next five years.\n\nsummary\nThere is a \"chronic\" need for more housing for prison leavers in Wales, according to a charity.\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import pipeline\n\n# Evaluate this using PEGASUS\npipe = pipeline(\"summarization\", model=\"google/pegasus-cnn_dailymail\", framework='pt')\npipe_out = pipe(dataset_samsum[\"test\"][0][\"document\"])\nprint(\"summary:\")\nprint(pipe_out[0][\"summary_text\"].replace(\" .<n>\", \".\\n\"))","metadata":{"execution":{"iopub.status.busy":"2023-05-12T21:50:05.709614Z","iopub.execute_input":"2023-05-12T21:50:05.710094Z","iopub.status.idle":"2023-05-12T21:51:07.026324Z","shell.execute_reply.started":"2023-05-12T21:50:05.710053Z","shell.execute_reply":"2023-05-12T21:51:07.022049Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"summary:\nSome ex-offenders are living rough for up to a year before finding accommodation.\nPrison Link Cymru had 1,099 referrals in 2015-16.\nCharity workers say investment in housing would be cheaper than jailing homeless repeat offenders.\nChanges to the Housing Act in Wales, introduced in 2015, removed the right for prison leavers to be given priority for accommodation .\n","output_type":"stream"}]},{"cell_type":"code","source":"print(pipe_out[0])","metadata":{"execution":{"iopub.status.busy":"2023-05-12T21:51:07.029985Z","iopub.execute_input":"2023-05-12T21:51:07.031830Z","iopub.status.idle":"2023-05-12T21:51:07.039451Z","shell.execute_reply.started":"2023-05-12T21:51:07.031789Z","shell.execute_reply":"2023-05-12T21:51:07.038434Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"{'summary_text': 'Some ex-offenders are living rough for up to a year before finding accommodation .<n>Prison Link Cymru had 1,099 referrals in 2015-16 .<n>Charity workers say investment in housing would be cheaper than jailing homeless repeat offenders .<n>Changes to the Housing Act in Wales, introduced in 2015, removed the right for prison leavers to be given priority for accommodation .'}\n","output_type":"stream"}]},{"cell_type":"code","source":"from tqdm import tqdm\nimport torch\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\ndef chunks(list_of_elements, batch_size):\n    for i in range(0, len(list_of_elements), batch_size):\n        yield list_of_elements[i : i + batch_size]\n\ndef evaluate_summaries(dataset, metric, model, tokenizer,\n                       batch_size=16, device=device,\n                       column_text=\"article\", column_summary=\"highlights\"):\n    article_batches = list(chunks(dataset[column_text], batch_size))\n    target_batches = list(chunks(dataset[column_summary], batch_size))\n\n    for article_batch, target_batch in tqdm(\n        zip(article_batches, target_batches), total=len(article_batches)):\n\n        inputs = tokenizer(article_batch, max_length=1024, truncation=True,\n                        padding=\"max_length\", return_tensors=\"pt\")\n\n        summaries = model.generate(input_ids=inputs[\"input_ids\"].to(device),\n                                   attention_mask=inputs[\"attention_mask\"].to(device),\n                                   length_penalty=0.8, num_beams=8, max_length=128)\n\n        decoded_summaries = [tokenizer.decode(s, skip_special_tokens=True,\n                                              clean_up_tokenization_spaces=True)\n                             for s in summaries]\n\n        decoded_summaries = [d.replace(\"<n>\", \" \") for d in decoded_summaries]\n        \n    return metric.compute(predictions=decoded_summaries, references=target_batch)","metadata":{"execution":{"iopub.status.busy":"2023-05-12T21:51:07.042040Z","iopub.execute_input":"2023-05-12T21:51:07.043615Z","iopub.status.idle":"2023-05-12T21:51:07.057211Z","shell.execute_reply.started":"2023-05-12T21:51:07.043555Z","shell.execute_reply":"2023-05-12T21:51:07.056168Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Load the model directly\nfrom transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n\nmodel_ckpt = \"ainize/bart-base-cnn\"\ntokenizer = AutoTokenizer.from_pretrained(model_ckpt)\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_ckpt).to(device)","metadata":{"execution":{"iopub.status.busy":"2023-05-12T21:51:07.061146Z","iopub.execute_input":"2023-05-12T21:51:07.062842Z","iopub.status.idle":"2023-05-12T21:51:15.207840Z","shell.execute_reply.started":"2023-05-12T21:51:07.062803Z","shell.execute_reply":"2023-05-12T21:51:15.206820Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"!pip install evaluate\n!pip install rouge_score\nimport evaluate\n\nrouge_metric = evaluate.load(\"rouge\")","metadata":{"execution":{"iopub.status.busy":"2023-05-12T21:51:15.209230Z","iopub.execute_input":"2023-05-12T21:51:15.209662Z","iopub.status.idle":"2023-05-12T21:51:39.899641Z","shell.execute_reply.started":"2023-05-12T21:51:15.209624Z","shell.execute_reply":"2023-05-12T21:51:39.898602Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nRequirement already satisfied: evaluate in /opt/conda/lib/python3.10/site-packages (0.4.0)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.14)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.18.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from evaluate) (1.23.5)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.28.2)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from evaluate) (4.64.1)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate) (1.5.3)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from evaluate) (21.3)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.13.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.2.0)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.6)\nRequirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2023.4.0)\nRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.1.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.8.4)\nRequirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (10.0.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (3.11.0)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (6.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->evaluate) (3.0.9)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.15)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.4)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2022.12.7)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2.1.1)\nRequirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.3)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.3)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (22.2.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.8.2)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->evaluate) (1.16.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nRequirement already satisfied: rouge_score in /opt/conda/lib/python3.10/site-packages (0.1.2)\nRequirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.16.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.23.5)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from rouge_score) (3.2.4)\nRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.4.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"score = evaluate_summaries(dataset_samsum[\"test\"], rouge_metric, model,\n                           tokenizer, column_text=\"document\",\n                           column_summary=\"summary\", batch_size=8)","metadata":{"execution":{"iopub.status.busy":"2023-05-12T21:51:39.902062Z","iopub.execute_input":"2023-05-12T21:51:39.902789Z","iopub.status.idle":"2023-05-12T23:10:02.848974Z","shell.execute_reply.started":"2023-05-12T21:51:39.902746Z","shell.execute_reply":"2023-05-12T23:10:02.847987Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"100%|██████████| 1417/1417 [1:18:22<00:00,  3.32s/it]\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\n\npd.DataFrame(score, index=[\"bart\"])","metadata":{"execution":{"iopub.status.busy":"2023-05-12T23:10:02.851197Z","iopub.execute_input":"2023-05-12T23:10:02.851487Z","iopub.status.idle":"2023-05-12T23:10:02.891034Z","shell.execute_reply.started":"2023-05-12T23:10:02.851461Z","shell.execute_reply":"2023-05-12T23:10:02.890092Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"        rouge1    rouge2    rougeL  rougeLsum\nbart  0.190064  0.021783  0.115375   0.144644","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>rouge1</th>\n      <th>rouge2</th>\n      <th>rougeL</th>\n      <th>rougeLsum</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>bart</th>\n      <td>0.190064</td>\n      <td>0.021783</td>\n      <td>0.115375</td>\n      <td>0.144644</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"def convert_examples_to_features(example_batch):\n    input_encodings = tokenizer(example_batch[\"document\"], truncation=True,\n                                max_length=1024)\n\n    with tokenizer.as_target_tokenizer():\n        target_encodings = tokenizer(example_batch[\"summary\"], max_length=128,\n                                     truncation=True)\n\n    return {\"input_ids\": input_encodings[\"input_ids\"],\n            \"attention_mask\": input_encodings[\"attention_mask\"],\n            \"labels\": target_encodings[\"input_ids\"]}\n\ndataset_samsum_pt = dataset_samsum.map(convert_examples_to_features,\n                                       batched=True)\n\ncolumns = [\"input_ids\", \"labels\", \"attention_mask\"]","metadata":{"execution":{"iopub.status.busy":"2023-05-12T23:10:02.892482Z","iopub.execute_input":"2023-05-12T23:10:02.893470Z","iopub.status.idle":"2023-05-12T23:15:19.923262Z","shell.execute_reply.started":"2023-05-12T23:10:02.893431Z","shell.execute_reply":"2023-05-12T23:15:19.922047Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/205 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b6606afe7de249e8afe6a9937a7b336b"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3596: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/12 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"447029f333ce4b93997243e5a4880a53"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/12 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9165f1ce454348c09bd7d2e4ffdfce0b"}},"metadata":{}}]},{"cell_type":"code","source":"from transformers import DataCollatorForSeq2Seq\n\nseq2seq_collator = DataCollatorForSeq2Seq(tokenizer, model=model)","metadata":{"execution":{"iopub.status.busy":"2023-05-12T23:15:19.924900Z","iopub.execute_input":"2023-05-12T23:15:19.927007Z","iopub.status.idle":"2023-05-12T23:15:19.934305Z","shell.execute_reply.started":"2023-05-12T23:15:19.926970Z","shell.execute_reply":"2023-05-12T23:15:19.933304Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"from transformers import TrainingArguments, Trainer\n\n# Gradient accumulation saves memory by updating the model only every X batches\ntraining_args = TrainingArguments(\n    output_dir=\"bart-samsum\", num_train_epochs=1, warmup_steps=500,\n    per_device_train_batch_size=1, per_device_eval_batch_size=1,\n    weight_decay=0.01, logging_steps=10, push_to_hub=False,\n    evaluation_strategy=\"steps\", eval_steps=500, save_steps=1e6,\n    gradient_accumulation_steps=16)","metadata":{"execution":{"iopub.status.busy":"2023-05-12T23:15:19.941435Z","iopub.execute_input":"2023-05-12T23:15:19.942964Z","iopub.status.idle":"2023-05-12T23:15:20.110885Z","shell.execute_reply.started":"2023-05-12T23:15:19.942803Z","shell.execute_reply":"2023-05-12T23:15:20.109864Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"trainer = Trainer(model=model, args=training_args,\n                  tokenizer=tokenizer, data_collator=seq2seq_collator,\n                  train_dataset=dataset_samsum_pt[\"train\"],\n                  eval_dataset=dataset_samsum_pt[\"validation\"])\n\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2023-05-12T23:15:20.113861Z","iopub.execute_input":"2023-05-12T23:15:20.115242Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmeetpatel05431\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.15.2 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.15.0"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20230512_231522-j2o463g9</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/meetpatel05431/huggingface/runs/j2o463g9' target=\"_blank\">silver-serenity-2</a></strong> to <a href='https://wandb.ai/meetpatel05431/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/meetpatel05431/huggingface' target=\"_blank\">https://wandb.ai/meetpatel05431/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/meetpatel05431/huggingface/runs/j2o463g9' target=\"_blank\">https://wandb.ai/meetpatel05431/huggingface/runs/j2o463g9</a>"},"metadata":{}},{"name":"stderr","text":"You're using a BartTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='3501' max='12752' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 3501/12752 1:25:34 < 3:46:15, 0.68 it/s, Epoch 0.27/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>2.316600</td>\n      <td>2.071031</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>2.151500</td>\n      <td>2.021414</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>2.278000</td>\n      <td>1.983023</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>2.102600</td>\n      <td>1.956639</td>\n    </tr>\n    <tr>\n      <td>2500</td>\n      <td>2.170500</td>\n      <td>1.940550</td>\n    </tr>\n    <tr>\n      <td>3000</td>\n      <td>2.054400</td>\n      <td>1.921085</td>\n    </tr>\n  </tbody>\n</table><p>\n    <div>\n      \n      <progress value='614' max='11332' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [  614/11332 00:13 < 03:51, 46.30 it/s]\n    </div>\n    "},"metadata":{}}]},{"cell_type":"code","source":"# Evaluate after finetuning\nscore = evaluate_summaries(\n    dataset_samsum[\"test\"], rouge_metric, trainer.model, tokenizer,\n    batch_size=2, column_text=\"document\", column_summary=\"summary\")\npd.DataFrame(score, index=[f\"bart_finetuned\"])","metadata":{"execution":{"iopub.status.busy":"2023-05-13T03:46:07.475061Z","iopub.execute_input":"2023-05-13T03:46:07.475451Z","iopub.status.idle":"2023-05-13T04:26:58.450370Z","shell.execute_reply.started":"2023-05-13T03:46:07.475421Z","shell.execute_reply":"2023-05-13T04:26:58.447704Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":"100%|██████████| 5667/5667 [40:50<00:00,  2.31it/s]\n","output_type":"stream"},{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"                  rouge1    rouge2    rougeL  rougeLsum\nbart_finetuned  0.224641  0.046612  0.112321   0.112321","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>rouge1</th>\n      <th>rouge2</th>\n      <th>rougeL</th>\n      <th>rougeLsum</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>bart_finetuned</th>\n      <td>0.224641</td>\n      <td>0.046612</td>\n      <td>0.112321</td>\n      <td>0.112321</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"sample_text = dataset_samsum[\"test\"][0][\"document\"]\nreference = dataset_samsum[\"test\"][0][\"summary\"]\n\ninputs = tokenizer(sample_text, max_length=1024, truncation=True,\n                   padding=\"max_length\", return_tensors=\"pt\")\n\nsummaries = model.generate(input_ids=inputs[\"input_ids\"].to(device),\n                           attention_mask=inputs[\"attention_mask\"].to(\n    device),\n    length_penalty=0.8, num_beams=8, max_length=128)\n\ndecoded_summaries = [tokenizer.decode(s, skip_special_tokens=True,\n                                      clean_up_tokenization_spaces=True)\n                     for s in summaries]\n\ndecoded_summaries = [d.replace(\"<n>\", \" \") for d in decoded_summaries]","metadata":{"execution":{"iopub.status.busy":"2023-05-13T04:27:32.123333Z","iopub.execute_input":"2023-05-13T04:27:32.123747Z","iopub.status.idle":"2023-05-13T04:27:32.462886Z","shell.execute_reply.started":"2023-05-13T04:27:32.123716Z","shell.execute_reply":"2023-05-13T04:27:32.461771Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"print(decoded_summaries)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-13T04:27:33.087392Z","iopub.execute_input":"2023-05-13T04:27:33.087796Z","iopub.status.idle":"2023-05-13T04:27:33.095451Z","shell.execute_reply.started":"2023-05-13T04:27:33.087763Z","shell.execute_reply":"2023-05-13T04:27:33.094285Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"['More than 1,000 homeless people have been referred for accommodation in Wales since their release from prison, a charity has said.']\n","output_type":"stream"}]},{"cell_type":"code","source":"#References\n# This code was inspired by ajdillhoff/CSE6363:\n#https://github.com/ajdillhoff/CSE6363/blob/main/natural_language_processing/finetune_summarization.ipynb","metadata":{"execution":{"iopub.status.busy":"2023-05-13T04:27:36.645248Z","iopub.execute_input":"2023-05-13T04:27:36.645658Z","iopub.status.idle":"2023-05-13T04:27:36.653602Z","shell.execute_reply.started":"2023-05-13T04:27:36.645624Z","shell.execute_reply":"2023-05-13T04:27:36.652573Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}